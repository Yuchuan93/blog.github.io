{"meta":{"title":"Rich One","subtitle":null,"description":"","author":"Rich One","url":"https://yuchuan93.github.io","root":"/blog/"},"pages":[{"title":"归档","date":"2020-06-12T15:02:30.000Z","updated":"2021-05-13T14:04:38.187Z","comments":true,"path":"archives/index.html","permalink":"https://yuchuan93.github.io/archives/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-06-12T15:19:39.000Z","updated":"2021-05-13T14:04:27.416Z","comments":true,"path":"categories/index.html","permalink":"https://yuchuan93.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-07-10T13:57:48.000Z","updated":"2021-05-13T14:04:14.309Z","comments":true,"path":"tags/index.html","permalink":"https://yuchuan93.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"模糊算法","slug":"Blur","date":"2021-06-09T14:55:05.000Z","updated":"2021-07-07T15:02:27.176Z","comments":true,"path":"2021/06/09/Blur/","link":"","permalink":"https://yuchuan93.github.io/2021/06/09/Blur/","excerpt":"","text":"卷积核与卷积​ 在图像处理中，卷积操作指的就是使用一个卷积核 （kernel） 对一张图像中的每个像素进行一系列操作。卷积核通常是一个四方形网格结构（例如2×2、3×3的方形区域），该区域内每个方格都有一个权重值。当对图像中的某个像素进行卷积时，我们会把卷积核的中心放置于该像素上，如图12.4所示，翻转核之后再依次计算核中每个元素和其覆盖的图像像素值的乘积并求和，得到的结果就是该位置的新像素值。 ​ 比如上图，使用一个3×3大小的卷积核对一张5×5大小的图像进行卷积操作，当计算图中红色方块对应的像素的卷积结果时，我们首先把卷积核的中心放置在该像素位置，翻转核之后再依次计算核中每个元素和其覆盖的图像像素值的乘积并求和，得到新的像素值。 均值模糊​ 还是如上面的图片所示，使用一个3x3的卷积核，当然也可以是2x2（可以使用4个角或者上下左右都行，看情况）、5x5，只要核内的每个元素的值的权重是相等的，就是均值模糊。 降采样​ 在进行模糊算法的时候可以对原图像进行尺寸的压缩，不仅达到了模糊的效果，还提高了性能。 高斯模糊​ 高斯模糊同样利用了卷积计算，它使用的卷积核名为高斯核。高斯核是一个正方形大小的滤波核，其中每个元素的计算都是基于下面的高斯方程： G(x,y)=\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}​ 其中，σ 是标准方差（一般取值为1），x 和y 分别对应了当前位置到卷积核中心的整数距离。要构建一个高斯核，我们只需要计算高斯核中各个位置对应的高斯值。为了保证滤波后的图像不会变暗，我们需要对高斯核中的权重进行归一化，即让每个权重除以所有权重的和，这样可以保证所有权重的和为1。因此，高斯函数中e 前面的系数实际不会对结果有任何影响。下方左图显示了一个标准方差为1的5×5大小的高斯核。 ​ 高斯方程很好地模拟了邻域每个像素对当前处理像素的影响程度——距离越近，影响越大。高斯核的维数越高，模糊程度越大。使用一个NxN的高斯核对图像进行卷积滤波，就需要N×N×W×H（W和H分别是图像的宽和高）次纹理采样。当N的大小不断增加时，采样次数会变得非常巨大。幸运的是，我们可以把这个二维高斯函数拆分成两个一维函数。也就是说，我们可以使用两个一维的高斯核（右图）先后对图像进行滤波，它们得到的结果和直接使用二维高斯核是一样的，但采样次数只需要2×N×W×H。我们可以进一步观察到，两个一维高斯核中包含了很多重复的权重。对于一个大小为5的一维高斯核，我们实际只需要记录3个权重值即可。 这里的二维高斯函数拆分成一维函数用到了高斯函数的分离特性，即 G(x,y)=G(x)*G(y)推导过程： G(x,y)=\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}=\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2}{2\\sigma^2}-\\frac{y^2}{2\\sigma^2}} =\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2}{2\\sigma^2}}*\\frac{1}{2\\pi\\sigma^2}e^{-\\frac{y^2}{2\\sigma^2}}=G(x)*G(y)​ 使用横向的一维高斯核对图像进行滤波后，再使用纵向的高斯核进行一次滤波，得到最终图像就是高斯模糊算法的过程。并且我们能够通过调整滤波的应用次数来控制模糊程度，使用降采样来进一步提高性能。 高斯模糊实现​ 均值模糊核高斯模糊只是卷积核不同，所以这里就只记录一下高斯模糊的实现 Shader代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103Shader &quot;Unlit/GaussianBlur&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; &#125; SubShader &#123; CGINCLUDE #include &quot;UnityCG.cginc&quot; sampler2D _MainTex; float2 _MainTex_TexelSize; float _BlurSize; struct v2f &#123; float2 uv[5] : TEXCOORD0; float4 vertex : SV_POSITION; &#125;; v2f vertVertical(appdata_img v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); float2 uv = v.texcoord; o.uv[0] = uv; o.uv[1] = uv + float2(0.0, _MainTex_TexelSize.y) * _BlurSize; o.uv[2] = uv + float2(0.0, -_MainTex_TexelSize.y) * _BlurSize; o.uv[3] = uv + float2(0.0, _MainTex_TexelSize.y * 2) * _BlurSize; o.uv[4] = uv + float2(0.0, -_MainTex_TexelSize.y * 2) * _BlurSize; return o; &#125; v2f vertHorizontal(appdata_img v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); float2 uv = v.texcoord; o.uv[0] = uv; o.uv[1] = uv + float2(_MainTex_TexelSize.x, 0.0) * _BlurSize; o.uv[2] = uv + float2(-_MainTex_TexelSize.x, 0.0) * _BlurSize; o.uv[3] = uv + float2( _MainTex_TexelSize.x * 2, 0.0) * _BlurSize; o.uv[4] = uv + float2(-_MainTex_TexelSize.x * 2, 0.0) * _BlurSize; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; // 只需要记录3个值 float weight[3] = &#123;0.4026, 0.2442, 0.0545&#125;; fixed3 sum = tex2D(_MainTex, i.uv[0]).rgb * weight[0]; for(int ite = 1; ite &lt; 3; ite++) &#123; sum += tex2D(_MainTex, i.uv[ite*2-1]).rgb * weight[ite]; sum += tex2D(_MainTex, i.uv[ite*2]).rgb * weight[ite]; &#125; return fixed4(sum, 1); &#125; ENDCG ZTest Always Cull Off ZWrite Off Pass &#123; // 垂直方向上的模糊 NAME &quot;GAUSSIAN_BLUR_VERTICAL&quot; CGPROGRAM #pragma vertex vertVertical #pragma fragment frag ENDCG &#125; Pass &#123; // 水平方向上的模糊 NAME &quot;GAUSSIAN_BLUR_HORIZONTAL&quot; CGPROGRAM #pragma vertex vertHorizontal #pragma fragment frag ENDCG &#125; &#125;&#125; c#脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455using UnityEngine;public class MyBlur : PostEffectsBase&#123; [SerializeField] Material mat; [SerializeField] [Range(0, 10)] int iteration = 3; [SerializeField] [Range(1, 32)] int downSample = 32; [SerializeField] [Range(0, 3)] float blurSpread = 1; private void OnRenderImage(RenderTexture source, RenderTexture destination) &#123; int width = Screen.width / downSample; int height = Screen.height / downSample; RenderTexture buffer0 = RenderTexture.GetTemporary(width, height, 0); Graphics.Blit(source, buffer0); for (int i = 0; i &lt; iteration; i++) &#123; mat.SetFloat(&quot;_BlurSize&quot;, 1.0f + i * blurSpread); RenderTexture buffer1 = RenderTexture.GetTemporary(width, height); // Render Vertical Pass Graphics.Blit(buffer0, buffer1, mat, 0); RenderTexture.ReleaseTemporary(buffer0); buffer0 = buffer1; buffer1 = RenderTexture.GetTemporary(width, height, 0); // Render Horizontal Pass Graphics.Blit(buffer0, buffer1, mat, 1); RenderTexture.ReleaseTemporary(buffer0); buffer0 = buffer1; &#125; Graphics.Blit(buffer0, destination); RenderTexture.ReleaseTemporary(buffer0); &#125;&#125; 最终效果：","categories":[],"tags":[{"name":"shader","slug":"shader","permalink":"https://yuchuan93.github.io/tags/shader/"}]},{"title":"在URP下渲染透明物体到深度纹理","slug":"TransparentDepth","date":"2021-04-03T14:50:18.000Z","updated":"2021-05-13T14:45:44.743Z","comments":true,"path":"2021/04/03/TransparentDepth/","link":"","permalink":"https://yuchuan93.github.io/2021/04/03/TransparentDepth/","excerpt":"深度纹理在Unity的URP管线环境下，我们可以在管线设置中打开深度纹理直接供我们使用，相较于默认管线更为方便。这个深度纹理一般会用到后处理效果上，比如Unity内置的景深效果。","text":"深度纹理在Unity的URP管线环境下，我们可以在管线设置中打开深度纹理直接供我们使用，相较于默认管线更为方便。这个深度纹理一般会用到后处理效果上，比如Unity内置的景深效果。 URP的深度纹理实现Unity会根据情况，用两种不同的方式来实现深度纹理，一个是CopyDepth，一个是DepthPrepass。 CopyDepthCopyDepth是在执行完非透明物体时会从深度缓冲中复制一份出来，可以很明显的判断出，这个深度是不包含透明物体的，因为渲染队列排在透明物体的前面，但是就算将队列放到透明物体后面，也不能保证透明物体在渲染的时候就一定会写入深度，通常情况下透明物体一般都不会写入深度。 DepthPrepass在某些情况下，比如开启了抗锯齿，Unity则会使用DepthPrepass的方式来渲染深度纹理，这个方式会提前将场景中物体的深度渲染一遍，使用的是物体本身Shader中PassTag为DepthOnly的pass。但是透明物体也还是被排除在外，我们通过源码看到，只有渲染队列为Opaque的物体会参与计算。 图1-1 下图是一个实例场景，三个cube，使用的shader是Lit，红色的是透明的，其他的是非透明的，红色和蓝色是距离摄像机位置相同，绿色的距离稍远，然后添加了景深后处理效果。 图1-2 可以看到，红色由于是透明物体，并没有正确的景深效果。我们打开FrameDebug，发现无论是CopyDepth还是DepthPrepass，都没有渲染透明物体。 图1-3 图1-4 渲染透明物体的深度如果我们使用CopyDepth的方式来渲染透明深度就需要打开透明物体的深度写入，将深度写入到深度缓冲，然后将CopyDepth的队列放到透明物体后。但是这样的话会存在一个问题，就是不能保证透明物体的渲染正确。所以我这里选择用DepthOnly的方式来实现。 修改DepthOnlyPass的队列设置根据图1-1可以看到，在构造DepthPrepass时传入了一个RenderQueueRange类型，进入这个类可以发现，其实有三个选项可以选，Opaque、Transparent和All。 图2-1 直接修改为all试一下。 图2-2 图2-3 深度写入成功了，景深效果也正常了。当然这样直接修改是不行的，所以接下来就是用一个更灵活、破坏性更小的方式来实现了。我们可以自己实现一个和DepthOnlyPass功能一样的RenderFeature来渲染一次深度，但是我觉得这样也不好，因为URP的实现里，无论我们是否打开深度纹理，我们使用的后处理需要用到深度纹理的话，Unity都会使用CopyDepth和DepthPrepass其中一个进行渲染，我们不能将这两个渲染操作全部关闭，也就相当于如果使用自定义的RenderFeature的话会多出一次渲染深度的操作。所以我使用了另一种方式，就是修改了DepthPrepass初始化的方式，通过设置来决定是否渲染透明物体的深度。 首先找到RenderObjects类，在RenderQueueType这个枚举中添加All字段，后面就直接用这个枚举了，当然也可以自己定义一个，不过放在这里可以在后面将RenderObjects这个RenderFeature一并扩展了。 图2-4 然后为DepthOnlyPass添加一个新的构造方法。 图2-5 然后找到UniversalRenderPipelineAsset类，再到General settings的部分添加这个设置，并添加访问函数，同时在编辑器类中也添加对应代码。 这时，就可以看到管线资源中的变化了。 接下来我们修改DepthOnlyPass初始化的地方，这样就算是基本准备好了。 当然这里只是实现了最基本的修改，前面也说到过DepthPrepass的开启是需要一定条件的，比如开启抗锯齿。这里其实可以添加一个判断，如果开启了透明物体的渲染，就开启DepthPrepass这个选项，我这里就直接开启抗锯齿看效果了。 由于深度纹理多数都用于后处理效果，除了后处理，一些需要用到深度信息的效果，比如描边、水面等也都会用到，所以透明物体的深度基本是必需的。","categories":[],"tags":[{"name":"URP","slug":"URP","permalink":"https://yuchuan93.github.io/tags/URP/"}]},{"title":"实现一个可以溶解的平面投影阴影","slug":"ProjectorShadowDissolve","date":"2020-07-05T13:45:01.000Z","updated":"2020-07-12T12:42:36.892Z","comments":true,"path":"2020/07/05/ProjectorShadowDissolve/","link":"","permalink":"https://yuchuan93.github.io/2020/07/05/ProjectorShadowDissolve/","excerpt":"​ 最近项目项目上用到了平面投影阴影，原理是用一个单独的pass将模型顶点投影到一个平面上，这种方式有着不错的效率，但是也只能用在比较平的地面上，我们的项目刚好适用，而且还能跟随模型实现溶解的效果，一举两得。 先来看看怎么实现阴影原理​ 实现投影阴影其实就是计算每一个顶点沿着光线方向与投影平面的交点坐标，然后将该点以黑色渲染出来，想象一下将这个模型沿着光线方向一巴掌拍扁在平面上，就是这个意思。我们可以用相似三角形原理来求它，如下图：","text":"​ 最近项目项目上用到了平面投影阴影，原理是用一个单独的pass将模型顶点投影到一个平面上，这种方式有着不错的效率，但是也只能用在比较平的地面上，我们的项目刚好适用，而且还能跟随模型实现溶解的效果，一举两得。 先来看看怎么实现阴影原理​ 实现投影阴影其实就是计算每一个顶点沿着光线方向与投影平面的交点坐标，然后将该点以黑色渲染出来，想象一下将这个模型沿着光线方向一巴掌拍扁在平面上，就是这个意思。我们可以用相似三角形原理来求它，如下图： ​ ​ 现在问题转化为：已知B点和单位向量L（光照方向），求C点坐标。 ​ 由相似三角形定理，即对应边的比例相等，则有： -\\frac{Ly}{By}=\\frac{Lx}{Cx-Bx}​ 我们可以传入一个自定义的高度h，表示需要投影的平面高度： -\\frac{Ly}{By-h}=\\frac{Lx}{Cx-Bx}​ 那么就有： Cx=Bx-\\frac{Lx(By-h)}{Ly} Cy=h​ 现在我们是在二维平面下进行的推导，放到三维也是一样的。 实现​ 上代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061Pass &#123; Blend SrcAlpha OneMinusSrcAlpha ZWrite off CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; &#125;; struct v2f &#123; float4 vertex : SV_POSITION; float4 color : COLOR; &#125;; uniform float _PlaneHeight; uniform fixed3 _VirtualLightDir; uniform fixed3 _ShadowColor; float3 ShadowProjectPos(float4 vertPos) &#123; float3 shadowPos; //得到顶点的世界空间坐标 float3 worldPos = mul(unity_ObjectToWorld, vertPos).xyz; //灯光方向 float3 lightDir = normalize(_VirtualLightDir.xyz); //阴影的世界空间坐标（低于地面的部分不做改变） shadowPos.y = min(worldPos.y, _PlaneHeight); shadowPos.xz = worldPos.xz - lightDir.xz * max(0, worldPos.y - _PlaneHeight) / lightDir.y; return shadowPos; &#125; v2f vert (appdata v) &#123; v2f o; //得到阴影的世界空间坐标 float3 shadowPos = ShadowProjectPos(v.vertex); //转换到裁切空间 o.vertex = UnityWorldToClipPos(shadowPos); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; return fixed4(_ShadowColor, 1); &#125; ENDCG &#125; ​ 同时，我们需要从外部传入需要的参数，我这里直接在场景中创建一个空物体，挂上下面这个脚本，设置几个shader全局变量，也方便在场景中预览效果。 VirtualLight.cs12345678910111213141516171819using UnityEngine;[ExecuteInEditMode]public class VirtualLight : MonoBehaviour&#123; private int colorPropID = Shader.PropertyToID(&quot;_ShadowColor&quot;); private int lightDir = Shader.PropertyToID(&quot;_VirtualLightDir&quot;); private int heightPropID = Shader.PropertyToID(&quot;_PlaneHeight&quot;); public Color shadowColor; public float height; void Update() &#123; Shader.SetGlobalColor(colorPropID, shadowColor); Shader.SetGlobalFloat(heightPropID, height); Shader.SetGlobalVector(lightDir, transform.forward); &#125;&#125; ​ 到此，阴影效果就实现了，具体表现如下： ​ 但是遇到了问题，当调节阴影的透明度时，效果就不正常了，如下图。这是因为阴影是平面的，但是我们计算的顶点却不是，这会造成很多顶点会重合的覆盖在平面上，造成颜色的叠加，解决办法就是用模板测试，丢弃那些会重合的像素。 ​ 修改后的代码如下： 12345678910111213141516171819202122232425Pass &#123; Blend SrcAlpha OneMinusSrcAlpha ZWrite off Cull Back Stencil &#123; // 参考值，表示每个像素用这个值来进行测试 Ref 0 // 比较方式，如果模板值等于参考值则通过测试，模板值初始为0 Comp equal // 通过后模板值加1，这样后面的模板测试则不会通过了，保证一个像素只会填充一次 Pass incrWrap // 模板测试和深度测试失败，保持原来的模板值 Fail keep // 模板测试成功和深度测试失败，保持原来的模板值 ZFail keep &#125; CGPROGRAM -------- ENDCG &#125; 接下来就是溶解效果了原理​ 溶解就是利用透明度测试来实现，我们可以用一张灰度图来进行采样，然后再调节一个阈值，当采样到的值低于这个阈值时则抛弃这个像素。需要知道的是，我们不仅要模型本身要溶解，阴影也要溶解，所以两个pass都要进行同样的操作，这样会增加一次采样的消耗，不过不碍事，本次用到的灰度图如下： 实现​ 增加了溶解的shader完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148Shader &quot;Yuchuan/PlaneProjectorShadow&quot;&#123; Properties &#123; _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125; _DissolveMap(&quot;DissolveMap&quot;, 2D) = &quot;white&quot;&#123;&#125; _DissolveThreshold(&quot;DissolveThreshold&quot;, Range(0,1)) = 0 &#125; SubShader &#123; Tags &#123; &quot;RenderType&quot;=&quot;Opaque&quot; &#125; LOD 100 Pass &#123; Blend SrcAlpha OneMinusSrcAlpha ZWrite off Cull Back Stencil &#123; // 参考值，表示每个像素用这个值来进行测试 Ref 0 // 比较方式，如果模板值等于参考值则通过测试，模板值初始为0 Comp equal // 通过后模板值加1，这样后面的模板测试则不会通过了，保证一个像素只会填充一次 Pass incrWrap // 模板测试和深度测试失败，保持原来的模板值 Fail keep // 模板测试成功和深度测试失败，保持原来的模板值 ZFail keep &#125; CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; &#125;; struct v2f &#123; float4 vertex : SV_POSITION; float4 color : COLOR; float2 uv : TEXCOORD0; &#125;; uniform float _PlaneHeight; uniform fixed3 _VirtualLightDir; uniform fixed4 _ShadowColor; sampler2D _DissolveMap; float _DissolveThreshold; float3 ShadowProjectPos(float4 vertPos) &#123; float3 shadowPos; //得到顶点的世界空间坐标 float3 worldPos = mul(unity_ObjectToWorld, vertPos).xyz; //灯光方向 float3 lightDir = normalize(_VirtualLightDir.xyz); //阴影的世界空间坐标（低于地面的部分不做改变） shadowPos.y = min(worldPos.y, _PlaneHeight); shadowPos.xz = worldPos.xz - lightDir.xz * max(0, worldPos.y - _PlaneHeight) / lightDir.y; return shadowPos; &#125; v2f vert (appdata v) &#123; v2f o; //得到阴影的世界空间坐标 float3 shadowPos = ShadowProjectPos(v.vertex); //转换到裁切空间 o.vertex = UnityWorldToClipPos(shadowPos); o.uv = v.uv; return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed4 mask = tex2D(_DissolveMap, i.uv); if (mask.r &lt; _DissolveThreshold) discard; return _ShadowColor; &#125; ENDCG &#125; Pass &#123; CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;UnityCG.cginc&quot; struct appdata &#123; float4 vertex : POSITION; float2 uv : TEXCOORD0; &#125;; struct v2f &#123; float2 uv : TEXCOORD0; float3 worldNormal : TEXCOORD1; float4 vertex : SV_POSITION; &#125;; sampler2D _MainTex; float4 _MainTex_ST; sampler2D _DissolveMap; float _DissolveThreshold; v2f vert (appdata v) &#123; v2f o; o.vertex = UnityObjectToClipPos(v.vertex); o.worldNormal = UnityObjectToWorldNormal(v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); return o; &#125; fixed4 frag (v2f i) : SV_Target &#123; fixed4 col = tex2D(_MainTex, i.uv); fixed4 mask = tex2D(_DissolveMap, i.uv); if (mask.r &lt; _DissolveThreshold) discard; return col; &#125; ENDCG &#125; &#125;&#125; 最终成品：","categories":[],"tags":[{"name":"shader","slug":"shader","permalink":"https://yuchuan93.github.io/tags/shader/"}]},{"title":"开始吧","slug":"MyFirstBlog","date":"2020-06-12T15:22:20.000Z","updated":"2020-07-07T17:09:10.192Z","comments":true,"path":"2020/06/12/MyFirstBlog/","link":"","permalink":"https://yuchuan93.github.io/2020/06/12/MyFirstBlog/","excerpt":"为什么要建博客​ 花了几天时间，终于有了一个属于自己的博客，虽然我是一个工作几年的程序员，但搭建这个博客也还是耗费了些许精力，真是惭愧。我为什么想要弄一个自己的博客呢？其实这个想法很早就有了，但是一直因为各种原因（我不会说是因为拖延症）一直没有着手。直到最近，我突然发现工作了几年下来，总是感觉缺了点什么，没有自己能看得见的积累，自身的成长也很慢，我虽然一直对未来没有很迷茫，但目前多少有点不知所措，所以这个博客也算是很有必要了。","text":"为什么要建博客​ 花了几天时间，终于有了一个属于自己的博客，虽然我是一个工作几年的程序员，但搭建这个博客也还是耗费了些许精力，真是惭愧。我为什么想要弄一个自己的博客呢？其实这个想法很早就有了，但是一直因为各种原因（我不会说是因为拖延症）一直没有着手。直到最近，我突然发现工作了几年下来，总是感觉缺了点什么，没有自己能看得见的积累，自身的成长也很慢，我虽然一直对未来没有很迷茫，但目前多少有点不知所措，所以这个博客也算是很有必要了。 这个博客要写些什么​ 首先会写的肯定是我的主业相关，也就是Unity游戏开发的相关内容，这可能会包括引擎相关技术、功能实现、渲染等；然后就是在工作中遇到的技术问题，这个博客一大用处就是在你解决问题后能将它记录下来，在记录的过程中也便于自己加深理解；除了这些技术相关的博文，我肯定还会有其他想要记录的东西，只是现在我还没有纳入或者说还没有发现。 我期望这个博客能带来什么成长​ 希望我能通过这个博客改变我现有的一些工作方式，慢慢学习去记录，通过记录来提高对陌生知识的吸收效率，让自己的成长更快。 分享​ 把遇到的问题或者一些自己感觉到很酷的东西分享出来，不再自己一个人埋头苦干，如果有人能看到，然后能跟你交流，这也是一种快乐吧！","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"shader","slug":"shader","permalink":"https://yuchuan93.github.io/tags/shader/"},{"name":"URP","slug":"URP","permalink":"https://yuchuan93.github.io/tags/URP/"}]}